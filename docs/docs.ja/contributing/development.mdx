---
title: 開発環境の構築
sidebar_position: 3
version: 1
---
# 開発環境の構築

このセクションのドキュメントは、Superset (`docker compose`、単に "docker"、"metal" 上、Makefile を使用) を実行するためのさまざまな方法を表す知識の寄せ集めのようなものです。

:::note
現在、私たちは開発環境におけるSupersetの実行方法として、より積極的に`docker compose`を推奨・サポートするようになりました。これは、皆さんの健全な精神を保つためです。**ほとんどの方は、最初の数セクション（「Fork & Clone」、「docker compose」、「開発ツールのインストール」）に注力してください。**
:::

## フォークとクローン

まず、[GitHub でリポジトリをフォーク](https://help.github.com/articles/about-forks/)し、クローンを作成します。

次に、メインリポジトリを直接クローンすることもできますが、プルリクエストを送信することはできません。

```bash
git clone git@github.com:your-username/superset.git
cd superset
```

## docker compose (推奨!)

Superset の任意の場所に「Hello World」を組み込むための設定は、次のように簡単です。

```bash
# getting docker compose to fire up services, and rebuilding if some docker layers have changed
# using the `--build` suffix may be slower and optional if layers like py dependencies haven't changed
docker compose up --build
```

以下の点にご注意ください:

- これにより、Docker イメージがプル/ビルドされ、以下のサービスを含むクラスタが実行されます:
  - Superset  **Flask Web サーバー**。ローカル Python リポジトリ/コードをマウントします。
  - Superset  **Celery ワーカー**。ローカル Python リポジトリ/コードをマウントします。
  - Superset  **Node サービス**。JS/TS アセットのマウント、コンパイル、バンドルを行います。
  - Superset  **Node Websocket サービス**。非同期バックエンドの基盤となります。
  - メタデータデータベースとして、また起動時に入力されるサンプルデータセット、チャート、ダッシュボードの保存用として **Postgres** を使用します。
  - 非同期バックエンドとキャッシュバックエンドのメッセージキューとして **Redis** を使用します。
- 初回起動時にデータベースにサンプルがロードされます。
- その他の詳細とポインタは [docker-compose.yml](https://github.com/apache/superset/blob/master/docker-compose.yml) で参照できます。
- ローカルリポジトリはサービス内にマウントされるため、ホスト上のコードを更新すると Docker イメージにも反映されます。
- Superset は localhost:9000/ で提供されます。
- admin/admin でログインできます。

:::note
`superset-node` 内での Apache Superset 用 Node モジュールのインストールとビルドには、かなりの時間がかかる場合があります。これは、依存関係のサイズが大きいため、正常な動作です。処理が完了するまでしばらくお待ちください。待ち時間が長くても、セットアップに問題があるわけではありません。
遅延が長すぎると思われる場合は、インターネット接続またはシステムリソースを確認してください。
:::

:::caution
`docker compose` は主に **単一ホスト** 上でコンテナセットを実行するように設計されており、結果として **高可用性** を確実にサポートできないため、本番環境のユースケースをサポートするために `docker compose` 構造を使用することはサポートも推奨もしていません。
単一ホスト環境では、[k8s へのインストール](https://superset.apache.org/docs/installation/running-on-kubernetes) ドキュメントに沿って [minikube](https://minikube.sigs.k8s.io/docs/start/) を使用することをお勧めします。
安全に構成されています。
:::

### サポートされている環境変数

Docker ビルドプロセスに影響するもの:

- **SUPERSET_BUILD_TARGET (デフォルト=dev):** ビルドする --target。一般的には `lean` または `dev` が使用されます。
- **INCLUDE_FIREFOX (デフォルト=false):** ビルドに Firefox のヘッドレスブラウザを含めるかどうか。
- **INCLUDE_CHROMIUM (デフォルト=false):** ビルドに Firefox のヘッドレスブラウザを含めるかどうか。
- **BUILD_TRANSLATIONS(デフォルト=false):** 利用可能な .po ファイルから翻訳をコンパイルするかどうか。
- **SUPERSET_LOAD_EXAMPLES (デフォルト=yes):** 起動時にサンプルをデータベースにロードするかどうか。`SUPERSET_LOAD_EXAMPLES=no docker compose up` とすることで、起動時の貴重な時間を節約できます。
- **SUPERSET_LOG_LEVEL (デフォルト=info)**: より詳細なログ出力を行うには、debug、info、warning、error、critical に設定できます。

構成に影響するその他の env 変数については、`docker compose` コンテキストで env 変数をスーパーセット構成に割り当てるために使用される [superset_config.py](https://github.com/apache/superset/blob/master/docker/pythonpath_dev/superset_config.py) を参照してください。

### PostgreSQL データベースへのアクセス

Docker コンテナ内のデータベースに直接アクセスすると便利な場合があります。
次のコマンドを実行すると、`p​​sql` シェル（公式 PostgreSQL クライアント）を起動できます。

```bash
docker compose exec db psql -U superset
```

また、データベースはポート 5432 で公開されているため、`localhost:5432` への新しいデータベース接続を作成することにより、お気に入りの Postgres クライアントまたは SQL Lab 自体を使用して Superset で直接データベースに接続できることにも注意してください。

### PostgreSQL データベースの完全削除

場合によっては、開発データベースの状態が悪化してしまうことがあります。例えば、マイグレーションを含むブランチを切り替える際によく発生します。この場合、`alembic` が管理するデータベースのバージョンスタンプが、ブランチ切り替え後に利用できなくなります。

このような場合、PostgreSQLデータベースを完全に削除して、最初からやり直すのが簡単な解決策です。ただし、これを行うとデータベースの状態が完全に失われるため、注意が必要です。

```bash
# first stop docker-compose if it's running
docker-compose down
# delete the volume containing the database
docker volume rm superset_db_home
# restart docker-compose, which will init a fresh database and load examples
docker-compose up
```

## 開発ツールのインストール

:::note
`docker compose` はセットアップの多くを簡素化しますが、IDE を強化するためにローカルでセットアップする必要があるものもまだたくさんあります。**コミットフック**、**リンター**、**テストランナー** などです。これらの作業は、例えば `docker compose exec superset_app bash` コマンドを使って docker イメージ内で実行できますが、多くの人はホストからツールを実行することを好みます。
:::

### Python 環境

`pyenv`、`virtualenv` などの Python 環境を既にセットアップしている場合は、[OS 依存関係](https://superset.apache.org/docs/installation/pypi/#os-dependencies) に記載されている前提条件をインストールした後、固定された Python 要件バンドルである dev をインストールするだけです。

```bash
pip install -r requirements/development.txt
```

### Git フック

Superset は、[pre-commit](https://pre-commit.com/) が提供する Git 事前コミットフックを使用します。
インストールするには、次のコマンドを実行します:

```bash
pre-commit install
```

これにより、ローカルリポジトリにフックがインストールされます。
今後は、Git コミットを行うたびに、一連のチェックが自動的に実行されます。

#### 手動での pre-commit の実行

pre-commit チェックは、以下の方法で手動で実行することもできます。

- **すべてのファイルに対して pre-commit を実行する（CI と同じ）**

  リポジトリ内のすべてのファイルに対してコミット前のチェックを実行するには、次のコマンドを使用します:

  ```bash
  pre-commit run --all-files
  ```

  これは CI 中に実行されるチェックと同じセットであり、変更がプロジェクトの標準を満たしていることを確認します。

- **特定のファイルに対して事前コミットを実行します:**

  特定のファイルを確認または修正したい場合は、ファイル パスを指定して実行できます:

  ```bash
  pre-commit run --files path/to/your/file.py
  ```

  これにより、指定したファイルに対してのみチェックが実行されます。

- **特定のコミット前チェックを実行します:**

  すべてのファイルまたは特定のファイルに対して特定のチェック (フック) を実行するには、次のコマンドを使用します:

  ```bash
  pre-commit run <hook_id> --all-files
  ```

  または特定のファイルの場合:

  ```bash
  pre-commit run <hook_id> --files path/to/your/file.py
  ```

  `<hook_id>` を、実行したいフックのIDに置き換えてください。利用可能なフックのリストは `.pre-commit-config.yaml` ファイルに記載されています。

## `docker compose` の代替

:::caution
ドキュメントのこの部分は、`docker compose` を使わずに開発環境をセットアップする方法に関する情報が寄せ集めで、ドキュメント化やサポートの程度もまちまちです。このように多様な方法を維持し、複数の環境で確実に機能するようにすることは困難でした。
:::

### Flask サーバー

#### OS Dependencies

以下の手順を実行する前に、お使いのマシンが[OSの依存関係](https://superset.apache.org/docs/installation/pypi#os-dependencies)を満たしていることを確認してください。
MySQLもインストールする必要があります。

Python バージョン 3.9、3.10、または 3.11 を使用していることを確認してから、次に進みます:

```bash
# Create a virtual environment and activate it (recommended)
python3 -m venv venv # setup a python3 virtualenv
source venv/bin/activate

# Install external dependencies
pip install -r requirements/development.txt

# Install Superset in editable (development) mode
pip install -e .

# Initialize the database
superset db upgrade

# Create an admin user in your metadata database (use `admin` as username to be able to load the examples)
superset fab create-admin

# Create default roles and permissions
superset init

# Load some data to play with.
# Note: you MUST have previously created an admin user with the username `admin` for this command to work.
superset load-examples

# Start the Flask dev web server from inside your virtualenv.
# Note that your page may not have CSS at this point.
# See instructions below on how to build the front-end assets.
superset run -p 8088 --with-threads --reload --debugger --debug
```

または、Makefile 経由でインストールすることもできます

```bash
# Create a virtual environment and activate it (recommended)
$ python3 -m venv venv # setup a python3 virtualenv
$ source venv/bin/activate

# install pip packages + pre-commit
$ make install

# Install superset pip packages and setup env only
$ make superset

# Setup pre-commit only
$ make pre-commit
```

**注: FLASK_APP 環境変数は現在 `.flaskenv` で制御されているため、設定する必要はありません。ただし、必要な場合は `superset.app:create_app()` に設定してください。**

FAB 管理テンプレートに変更を加えた場合（FAB 管理テンプレートは、新しい React ベースのフロントエンドアセットとは異なる方法で構築されているため）、`--with-threads` 引数を省略してアプリを起動する必要があります。例:
`superset run -p 8088 --reload --debugger --debug`

#### 依存関係

新しい要件を追加したり、既存の要件を更新したりする場合（`setup.py` の `install_requires` セクションを参照）、CI やテストなどでビルドが確定的になるように、Python の依存関係を再コンパイル（フリーズ）する必要があります。これは、以下の方法で実現できます。

```bash
python3 -m venv venv
source venv/bin/activate
python3 -m pip install -r requirements/development.txt
./scripts/uv-pip-compile.sh
```

単一のパッケージのバージョン番号をアップグレードする場合は、`-P` フラグを付けて `./scripts/uv-pip-compile.sh` を実行する必要があります。

```bash
./scripts/uv-pip-compile.sh -P some-package-to-upgrade
```

`setup.py` と `requirements/*.in` で定義された制限に従ってすべての依存関係を最新の状態にするには、`./scripts/uv-pip-compile.sh --upgrade` を実行します。

```bash
./scripts/uv-pip-compile.sh --upgrade
```

これは定期的に実行する必要がありますが、ユニット テストと統合テストで検出されない重大な変更が導入されていないことを確認するために、アプリケーションの徹底的な手動テストを実行することをお勧めします。

#### ブラウザコンソールへのログイン

この機能はPython 3でのみ利用可能です。アプリケーションのデバッグ時に、[ConsoleLog](https://github.com/betodealmeida/consolelog)パッケージを使用すると、サーバーログをブラウザコンソールに直接送信できます。`config.py`または`superset_config.py`に以下のコードを追加して、アプリを変更する必要があります:

```python
from console_log import ConsoleLog

def FLASK_APP_MUTATOR(app):
    app.wsgi_app = ConsoleLog(app.wsgi_app, app.logger)
```

次に、適切なワーカー タイプを使用して WSGI サーバーを実行していることを確認します。

```bash
gunicorn "superset.app:create_app()" -k "geventwebsocket.gunicorn.workers.GeventWebSocketWorker" -b 127.0.0.1:8088 --reload
```

オブジェクトを含め、あらゆるものをブラウザ コンソールに記録できます:

```python
from superset import app
app.logger.error('An exception occurred!')
app.logger.info(form_data)
```

### フロントエンド

ウェブUIを正しく表示するには、フロントエンドアセット（TypeScript、JavaScript、CSS、画像）をコンパイルする必要があります。`superset-frontend`ディレクトリには、NPMで管理されるすべてのフロントエンドアセットが含まれています。一部のレガシーページには、Flask-Appbuilderにバンドルされた追加のフロントエンドアセット（jQueryやbootstrapなど）が含まれていることに注意してください。これらはNPMでは管理されておらず、将来的に廃止される可能性があります。

#### 前提条件

##### nvm と node

まず、次のバージョンの Node.js と npm を使用していることを確認してください:

- `Node.js`: Version 20
- `npm`: Version 10

ノード環境を管理するには、[nvm](https://github.com/nvm-sh/nvm) を使用することをお勧めします:

```bash
curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.37.0/install.sh | bash

in case it shows '-bash: nvm: command not found'
export NVM_DIR="$HOME/.nvm"
[ -s "$NVM_DIR/nvm.sh" ] && \. "$NVM_DIR/nvm.sh"  # This loads nvm
[ -s "$NVM_DIR/bash_completion" ] && \. "$NVM_DIR/bash_completion"  # This loads nvm bash_completion

cd superset-frontend
nvm install --lts
nvm use --lts
```

または、Catalina シェル `zsh` で始まるデフォルトの macOS を使用する場合は、次を試してください:

```zsh
sh -c "$(curl -fsSL https://raw.githubusercontent.com/nvm-sh/nvm/v0.37.0/install.sh)"
```

興味がある方は、[avn](https://github.com/nvm-sh/nvm#deeper-shell-integration) を試して、Superset フロントエンドの実行に必要なノード バージョンに自動的に切り替えることもできます。

#### 依存関係をインストールする

`package.json` にリストされているサードパーティの依存関係を次のようにインストールします:

```bash
# From the root of the repository
cd superset-frontend

# Install dependencies from `package-lock.json`
npm ci
```

Superset は [Scarf](https://docs.scarf.sh) を使用して、`scarf-js` npm パッケージや分析ピクセルなど、インストールされているバージョンに関するテレメトリ/分析を取得します。このドキュメントの他の箇所でも説明されているように、Scarf はセキュリティ/リリース戦略のために集計統計情報を収集しますが、PII を取得/保持することはありません。[こちら](https://docs.scarf.sh/package-analytics/) で `scarf-js` パッケージと、それをオプトアウトするさまざまな方法について読むことができますが、`SCARF_ANALYTICS` 環境変数を `false` に設定することで npm パッケージ _と_ ピクセルをオプトアウトするか、`superset-frontent/package.json` に次の設定を追加することでピクセルをオプトアウトできます:

```json
// your-package/package.json
{
  // ...
  "scarfSettings": {
    "enabled": false
  }
  // ...
}
```

#### アセットをビルドする

ビルドできるアセットは3種類あります:

1. `npm run build`: CSS/JSSを縮小・最適化した本番環境用アセット
2. `npm run dev-server`: ソースマップとホットリフレッシュに対応したローカル開発用アセット
3. `npm run build-instrumented`: Cypressテストからコードカバレッジを収集するためのインストルメント化されたアプリケーションコード

上記のコマンドの使用中に、ファイルウォッチャーの制限に関するエラーが発生した場合：

```bash
Error: ENOSPC: System limit for number of file watchers reached
```

このエラーは、システムによって監視されているファイル数が上限に達したために発生します。
inotify ウォッチャーの数を増やすことで、このエラーを解決できます。

現在の最大ウォッチャーの値は、次のコマンドで確認できます:

```bash
cat /proc/sys/fs/inotify/max_user_watches
```

この値を増やすには、`/etc/sysctl.conf` ファイルを編集してください。
この値はシステムメモリに基づいて決定する必要があります [(詳細については、StackOverflow の回答を参照してください)](https://stackoverflow.com/questions/535768/what-is-a-reasonable-amount-of-inotify-watches-with-linux)。

エディターでファイルを開き、末尾にウォッチの最大値を指定する行を追加してください。

```bash
fs.inotify.max_user_watches=524288
```

ファイルを保存してエディターを終了します。
変更が成功したことを確認するには、次のコマンドを実行して、`sysctl.conf` から更新された max_user_watches の値をロードします:

```bash
sudo sysctl -p
```

#### Webpack 開発サーバー

デフォルトでは、開発サーバーは `http://localhost:9000` で起動し、バックエンドリクエストを `http://localhost:8088` にプロキシします。

一般的な開発ワークフローは以下のとおりです。

1. Flask を使用して [Superset をローカルで実行](#flask-server) します。ポート `8088` を使用しますが、直接アクセスしないでください<br/>

   ```bash
   # Install Superset and dependencies, plus load your virtual environment first, as detailed above.
   superset run -p 8088 --with-threads --reload --debugger --debug
   ```

2. 並行して、Webpack開発サーバーをポート `9000` でローカルに実行します<br/>

   ```bash
   npm run dev-server
   ```

3. ウェブブラウザで `http://localhost:9000`（Webpackサーバー、Flaskではありません）にアクセスします。これにより、Webpack開発サーバーからホットリロードされたフロントエンドアセットが使用され、バックエンドクエリはFlask/Supersetにリダイレクトされます。Supersetコードベース（フロントエンドまたはバックエンド）への変更は、ブラウザにリアルタイムで反映されます。

Webpackサーバーの設定を変更することも可能です。

```bash
# Start the dev server at http://localhost:9000
npm run dev-server

# Run the dev server on a non-default port
npm run dev-server -- --port=9001

# Proxy backend requests to a Flask server running on a non-default port
npm run dev-server -- --env=--supersetPort=8081

# Proxy to a remote backend but serve local assets
npm run dev-server -- --env=--superset=https://superset-dev.example.com
```

`--superset=` オプションは、本番環境での問題をデバッグしたい場合や、ファイアウォールの内側に Superset をセットアップする必要がある場合に便利です。これにより、Flask サーバーを別の環境で実行しながら、アセットのビルドをローカルで維持し、最高の開発エクスペリエンスを実現できます。

#### その他の npm コマンド

他にも便利な NPM コマンドがあります。

1. `npm run build-dev`: 開発モードでアセットをビルドします。
2. `npm run dev`: 開発アセットをウォッチモードでビルドします。ファイルが変更されると自動的に再ビルドされます。

#### Docker (docker compose)

ドキュメントは[こちら](https://superset.apache.org/docs/installation/docker-compose)をご覧ください

#### NPM パッケージの更新

npm を規定の方法で使用し、`superset-frontend/package-lock.json` が `npm` で規定されたベストプラクティスに従って更新されていることを確認してください。

#### 機能フラグ

Superset はサーバー全体で利用可能な機能フラグシステムをサポートしており、機能の段階的な開発を容易にします。新しい機能フラグを追加するには、`superset_config.py` を以下のように変更するだけです:

```python
FEATURE_FLAGS = {
    'SCOPED_FILTER': True,
}
```

クライアントコードで同じフラグを使用する場合は、[@superset-ui/core](https://github.com/apache/superset/blob/master/superset-frontend/packages/superset-ui-core/src/utils/featureFlags.ts) の FeatureFlag TypeScript 列挙型にも追加します。例えば、

```typescript
export enum FeatureFlag {
  SCOPED_FILTER = "SCOPED_FILTER",
}
```

`superset/config.py` には `DEFAULT_FEATURE_FLAGS` が含まれていますが、これは `superset_config.py` の FEATURE_FLAGS で指定されたものによって上書きされます。
例えば、`superset/config.py` で `DEFAULT_FEATURE_FLAGS = { 'FOO': True, 'BAR': False }` と `superset_config.py` で `FEATURE_FLAGS = { 'BAR': True, 'BAZ': True }` を指定すると、機能フラグは `{ 'FOO': True, 'BAR': True, 'BAZ': True }` と結合されます。

各フラグの現在の使用状況（安定版かテスト版かなど）は、`RESOURCES/FEATURE_FLAGS.md` で確認できます。

## Gitフック

Supersetは、[pre-commit](https://pre-commit.com/) が提供するGitの事前コミットフックを使用します。インストールするには、以下のコマンドを実行してください:

```bash
pip3 install -r requirements/development.txt
pre-commit install
```

git コミットを行うと、一連のチェックが実行されるようになりました。

## リンティング

[ハウツー](/docs/contributing/howtos#linting) をご覧ください

## GitHub Actions と `act`

:::tip
Superset の GHA の `act` 互換性は完全にはテストされていません。
`act` をローカルで実行しても、アクションによっては動作しない可能性があり、微調整やローカルでのシークレット処理が必要になる場合があります。
ローカルでの実行が難しい複雑な GHA の場合は、ブランチに直接プッシュして GHA のログを監視することで、GHA のインフラストラクチャ上で直接反復処理することをお勧めします。
よりターゲットを絞った反復処理については、GitHub CLI の `gh workflow run --ref {BRANCH}` サブコマンドを参照してください。
:::

Superset は自動化と CI/CD のために GitHub Actions (GHA) を広範に活用しています。
すべてのワークフローとその他のアセットは `.github/` フォルダにあります。これには以下が含まれます。

- バックエンドのユニットテストスイート (`tests/`) の実行
- フロントエンドのテストスイート (`superset-frontend/src/**.*.test.*`) の実行
- Cypress のエンドツーエンドテスト (`superset-frontend/cypress-base/`) の実行
- Python、Typescript、Javascript、yaml などを含むコードベースの lint チェック
- その他さまざまなルールや規約のチェック

プルリクエスト（PR）を開くと、ブランチの変更内容に応じて適切なGitHub Actions（GHA）ワークフローが自動的に実行されます。
この自動化に頼るのは全く理にかなった（そして必須！）方法です。しかし、欠点は、ほぼ「オール・オア・ナッシング」のアプローチであり、特定のテストをターゲットにしたり、迅速に反復処理したりするための制御があまりできないことです。

GHAワークフローをローカルで実行する方が便利な場合もあります。
そのために、GitHub Actions (GHA)ワークフローをローカルで実行できるツールである[act](https://github.com/nektos/act)を使用します。
これはGitHub Actions環境をシミュレートし、開発者はリポジトリに変更をプッシュする前に、ローカルマシンでワークフローをテストおよびデバッグできます。
使用方法については、次のセクションで詳しく説明します。

:::note
GHAと`act`の両方で、より複雑なマトリックスでテストを実行し、異なるデータベースエンジン（PostgreSQL、MySQL、SQLite）と異なるバージョンのPythonに対して実行することができます。これにより、さまざまな環境間で互換性と安定性を確保できます。
:::

### `act` の使用

まず、`act` をインストールします -> https://nektosact.com/

ワークフローを一覧表示するには、以下の手順を実行します。

```bash
act --list
```

特定のワークフローを実行するには:

```bash
act pull_request --job {workflow_name} --secret GITHUB_TOKEN=$GITHUB_TOKEN --container-architecture linux/amd64
```

上記の例では、以下の点に注意してください。

- `--job` を使用して特定のワークフローをターゲットにしています。
- 多くのジョブはリポジトリへの読み取りアクセス（パブリック）を必要とするため、`--secret` を使用してシークレットを渡しています。
- 最初の引数として `pull_request` イベントを指定してシミュレートしています。同様に、`push` イベントやその他のイベントをシミュレートすることもできます。
- GHA をより確実にエミュレートするため、`--container-architecture` を指定しています。

:::note
`act` は、様々な機能を備えたリッチなツールです。pull_request、push などの様々なイベントのシミュレーションや、必要に応じてシークレットを渡すセマンティクスなど、様々な機能を備えています。詳細については、[act のドキュメント](https://nektosact.com/) をご覧ください。
:::

:::note
一部のジョブでは、外部システムやアカウントと連携するためにシークレットが必要になりますが、これらのシークレットはご自身では管理できない可能性があります。そのような場合は、リモートCIを利用するか、ジョブをさらにパラメータ化して、関連するシークレットに加えて、別の環境やサンドボックス、あるいは独自の環境やサンドボックスをターゲットとする必要があるかもしれません。
:::

---

## Testing

### Python Testing

#### Unit Tests

For unit tests located in `tests/unit_tests/`, it's usually easy to simply run the script locally using:

```bash
pytest tests/unit_tests/*
```

#### Integration Tests

For more complex pytest-defined integration tests (not to be confused with our end-to-end Cypress tests), many tests will require having a working test environment. Some tests require a database, Celery, and potentially other services or libraries installed.

### Running Tests with `act`

To run integration tests locally using `act`, ensure you have followed the setup instructions from the [GitHub Actions and `act`](#github-actions-and-act) section. You can run specific workflows or jobs that include integration tests. For example:

```bash
act --job test-python-38 --secret GITHUB_TOKEN=$GITHUB_TOKEN --event pull_request --container-architecture linux/amd64
```

#### Running locally using a test script

There is also a utility script included in the Superset codebase to run Python integration tests. The [readme can be found here](https://github.com/apache/superset/tree/master/scripts/tests).

There is also a utility script included in the Superset codebase to run python integration tests. The [readme can be
found here](https://github.com/apache/superset/tree/master/scripts/tests)

To run all integration tests, for example, run this script from the root directory:

```bash
scripts/tests/run.sh
```

You can run unit tests found in `./tests/unit_tests` with pytest. It is a simple way to run an isolated test that doesn't need any database setup:

```bash
pytest ./link_to_test.py
```

### Frontend Testing

We use [Jest](https://jestjs.io/) and [Enzyme](https://airbnb.io/enzyme/) to test TypeScript/JavaScript. Tests can be run with:

```bash
cd superset-frontend
npm run test
```

To run a single test file:

```bash
npm run test -- path/to/file.js
```

### Debugging Server App

#### Local

For debugging locally using VSCode, you can configure a launch configuration file .vscode/launch.json such as

```json
{
  "version": "0.2.0",
  "configurations": [
    {
      "name": "Python: Flask",
      "type": "python",
      "request": "launch",
      "module": "flask",
      "env": {
        "FLASK_APP": "superset",
        "SUPERSET_ENV": "development"
      },
      "args": ["run", "-p 8088", "--with-threads", "--reload", "--debugger"],
      "jinja": true,
      "justMyCode": true
    }
  ]
}
```

#### Raw Docker (without `docker compose`)

Follow these instructions to debug the Flask app running inside a docker container. Note that
this will run a barebones Superset web server,

First, add the following to the ./docker-compose.yaml file

```diff
superset:
    env_file: docker/.env
    image: *superset-image
    container_name: superset_app
    command: ["/app/docker/docker-bootstrap.sh", "app"]
    restart: unless-stopped
+   cap_add:
+     - SYS_PTRACE
    ports:
      - 8088:8088
+     - 5678:5678
    user: "root"
    depends_on: *superset-depends-on
    volumes: *superset-volumes
    environment:
      CYPRESS_CONFIG: "${CYPRESS_CONFIG}"
```

Start Superset as usual

```bash
docker compose up --build
```

Install the required libraries and packages to the docker container

Enter the superset_app container

```bash
docker exec -it superset_app /bin/bash
root@39ce8cf9d6ab:/app#
```

Run the following commands inside the container

```bash
apt update
apt install -y gdb
apt install -y net-tools
pip install debugpy
```

Find the PID for the Flask process. Make sure to use the first PID. The Flask app will re-spawn a sub-process every time you change any of the python code. So it's important to use the first PID.

```bash
ps -ef

UID        PID  PPID  C STIME TTY          TIME CMD
root         1     0  0 14:09 ?        00:00:00 bash /app/docker/docker-bootstrap.sh app
root         6     1  4 14:09 ?        00:00:04 /usr/local/bin/python /usr/bin/flask run -p 8088 --with-threads --reload --debugger --host=0.0.0.0
root        10     6  7 14:09 ?        00:00:07 /usr/local/bin/python /usr/bin/flask run -p 8088 --with-threads --reload --debugger --host=0.0.0.0
```

Inject debugpy into the running Flask process. In this case PID 6.

```bash
python3 -m debugpy --listen 0.0.0.0:5678 --pid 6
```

Verify that debugpy is listening on port 5678

```bash
netstat -tunap

Active Internet connections (servers and established)
Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name
tcp        0      0 0.0.0.0:5678            0.0.0.0:*               LISTEN      462/python
tcp        0      0 0.0.0.0:8088            0.0.0.0:*               LISTEN      6/python
```

You are now ready to attach a debugger to the process. Using VSCode you can configure a launch configuration file .vscode/launch.json like so.

```json
{
  "version": "0.2.0",
  "configurations": [
    {
      "name": "Attach to Superset App in Docker Container",
      "type": "python",
      "request": "attach",
      "connect": {
        "host": "127.0.0.1",
        "port": 5678
      },
      "pathMappings": [
        {
          "localRoot": "${workspaceFolder}",
          "remoteRoot": "/app"
        }
      ]
    }
  ]
}
```

VSCode will not stop on breakpoints right away. We've attached to PID 6 however it does not yet know of any sub-processes. In order to "wake up" the debugger you need to modify a python file. This will trigger Flask to reload the code and create a new sub-process. This new sub-process will be detected by VSCode and breakpoints will be activated.

### Debugging Server App in Kubernetes Environment

To debug Flask running in POD inside a kubernetes cluster, you'll need to make sure the pod runs as root and is granted the SYS_TRACE capability.These settings should not be used in production environments.

```yaml
  securityContext:
    capabilities:
      add: ["SYS_PTRACE"]
```

See [set capabilities for a container](https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-capabilities-for-a-container) for more details.

Once the pod is running as root and has the SYS_PTRACE capability it will be able to debug the Flask app.

You can follow the same instructions as in `docker compose`. Enter the pod and install the required library and packages; gdb, netstat and debugpy.

Often in a Kubernetes environment nodes are not addressable from outside the cluster. VSCode will thus be unable to remotely connect to port 5678 on a Kubernetes node. In order to do this you need to create a tunnel that port forwards 5678 to your local machine.

```bash
kubectl port-forward  pod/superset-<some random id> 5678:5678
```

You can now launch your VSCode debugger with the same config as above. VSCode will connect to 127.0.0.1:5678 which is forwarded by kubectl to your remote kubernetes POD.

### Storybook

Superset includes a [Storybook](https://storybook.js.org/) to preview the layout/styling of various Superset components and variations thereof. To open and view the Storybook:

```bash
cd superset-frontend
npm run storybook
```

When contributing new React components to Superset, please try to add a Story alongside the component's `jsx/tsx` file.

## Tips

### Adding a new datasource

1. Create Models and Views for the datasource, add them under superset folder, like a new my_models.py
   with models for cluster, datasources, columns and metrics and my_views.py with clustermodelview
   and datasourcemodelview.

1. Create DB migration files for the new models

1. Specify this variable to add the datasource model and from which module it is from in config.py:

   For example:

   ```python
   ADDITIONAL_MODULE_DS_MAP = {'superset.my_models': ['MyDatasource', 'MyOtherDatasource']}
   ```

   This means it'll register MyDatasource and MyOtherDatasource in superset.my_models module in the source registry.

### Visualization Plugins

The topic of authoring new plugins, whether you'd like to contribute
it back or not has been well documented in the
[the documentation](https://superset.apache.org/docs/contributing/creating-viz-plugins), and in [this blog post](https://preset.io/blog/building-custom-viz-plugins-in-superset-v2).

To contribute a plugin to Superset, your plugin must meet the following criteria:

- The plugin should be applicable to the community at large, not a particularly specialized use case
- The plugin should be written with TypeScript
- The plugin should contain sufficient unit/e2e tests
- The plugin should use appropriate namespacing, e.g. a folder name of `plugin-chart-whatever` and a package name of `@superset-ui/plugin-chart-whatever`
- The plugin should use theme variables via Emotion, as passed in by the ThemeProvider
- The plugin should provide adequate error handling (no data returned, malformed data, invalid controls, etc.)
- The plugin should contain documentation in the form of a populated `README.md` file
- The plugin should have a meaningful and unique icon
- Above all else, the plugin should come with a _commitment to maintenance_ from the original author(s)

Submissions will be considered for submission (or removal) on a case-by-case basis.

### Adding a DB migration

1. Alter the model you want to change. This example will add a `Column` Annotations model.

   [Example commit](https://github.com/apache/superset/commit/6c25f549384d7c2fc288451222e50493a7b14104)

1. Generate the migration file

   ```bash
   superset db migrate -m 'add_metadata_column_to_annotation_model'
   ```

   This will generate a file in `migrations/version/{SHA}_this_will_be_in_the_migration_filename.py`.

   [Example commit](https://github.com/apache/superset/commit/d3e83b0fd572c9d6c1297543d415a332858e262)

1. Upgrade the DB

   ```bash
   superset db upgrade
   ```

   The output should look like this:

   ```log
   INFO  [alembic.runtime.migration] Context impl SQLiteImpl.
   INFO  [alembic.runtime.migration] Will assume transactional DDL.
   INFO  [alembic.runtime.migration] Running upgrade 1a1d627ebd8e -> 40a0a483dd12, add_metadata_column_to_annotation_model.py
   ```

1. Add column to view

   Since there is a new column, we need to add it to the AppBuilder Model view.

   [Example commit](https://github.com/apache/superset/pull/5745/commits/6220966e2a0a0cf3e6d87925491f8920fe8a3458)

1. Test the migration's `down` method

   ```bash
   superset db downgrade
   ```

   The output should look like this:

   ```log
   INFO  [alembic.runtime.migration] Context impl SQLiteImpl.
   INFO  [alembic.runtime.migration] Will assume transactional DDL.
   INFO  [alembic.runtime.migration] Running downgrade 40a0a483dd12 -> 1a1d627ebd8e, add_metadata_column_to_annotation_model.py
   ```

### Merging DB migrations

When two DB migrations collide, you'll get an error message like this one:

```text
alembic.util.exc.CommandError: Multiple head revisions are present for
given argument 'head'; please specify a specific target
revision, '<branchname>@head' to narrow to a specific head,
or 'heads' for all heads`
```

To fix it:

1. Get the migration heads

   ```bash
   superset db heads
   ```

   This should list two or more migration hashes. E.g.

   ```bash
   1412ec1e5a7b (head)
   67da9ef1ef9c (head)
   ```

2. Pick one of them as the parent revision, open the script for the other revision
   and update `Revises` and `down_revision` to the new parent revision. E.g.:

   ```diff
   --- a/67da9ef1ef9c_add_hide_left_bar_to_tabstate.py
   +++ b/67da9ef1ef9c_add_hide_left_bar_to_tabstate.py
   @@ -17,14 +17,14 @@
   """add hide_left_bar to tabstate

   Revision ID: 67da9ef1ef9c
   -Revises: c501b7c653a3
   +Revises: 1412ec1e5a7b
   Create Date: 2021-02-22 11:22:10.156942

   """

   # revision identifiers, used by Alembic.
   revision = "67da9ef1ef9c"
   -down_revision = "c501b7c653a3"
   +down_revision = "1412ec1e5a7b"

   import sqlalchemy as sa
   from alembic import op
   ```

   Alternatively, you may also run `superset db merge` to create a migration script
   just for merging the heads.

   ```bash
   superset db merge {HASH1} {HASH2}
   ```

3. Upgrade the DB to the new checkpoint

   ```bash
   superset db upgrade
   ```
