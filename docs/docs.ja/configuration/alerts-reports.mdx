---
title: アラートとレポート
hide_title: true
sidebar_position: 2
version: 2
---

# アラートとレポート

ユーザーは、自動アラートとレポートを構成して、メール受信者またはスラックチャネルにダッシュボードまたはチャートを送信できます。

 -  *アラート* はSQL条件に到達したときに送信されます
 -  *レポート* はスケジュールで送信されます

アラートとレポートはデフォルトで無効になります。それらをオンにするには、ここで説明するセットアップを行う必要があります。

## 要件

### Commons

#### `superset_config.py` または `superset_config_docker.py` で

- `"ALERT_REPORTS"` [機能フラグ](/docs/configuration/configuring-superset#feature-flags) を True に設定する必要があります。
- CeleryConfig の `beat_schedule` に `reports.scheduler` のスケジュールが含まれている必要があります。
- 使用する内容に応じて、少なくとも 1 つを設定する必要があります。
    - メール: `SMTP_*` 設定
    - Slack メッセージ: `SLACK_API_TOKEN`
- ユーザーは、日付コードのプレースホルダを追加することでメールの件名をカスタマイズできます。日付コードのプレースホルダは、メール送信時に自動的に対応するUTC日付に置き換えられます。この機能を有効にするには、`"DATE_FORMAT_IN_EMAIL_SUBJECT"` [機能フラグ](/docs/configuration/configuring-superset#feature-flags) を有効にしてください。これにより、メールの件名に日付フォーマットが有効になり、すべてのレポートメールが同じスレッドにグループ化されるのを防ぐことができます（レポート機能ではオプションです）。
    - メールの件名を作成するには、[strftime.org](https://strftime.org/) の日付コードを使用します。
    - 日付コードが指定されていない場合は、元の文字列がメールの件名として使用されます。

##### ドライランモードを無効にする

`ALERT_REPORTS_NOTIFICATION_DRY_RUN = True`（`docker/pythonpath_dev/superset_config.py` のデフォルト値）に設定されている場合、スクリーンショットは撮影されますが、メッセージは送信されません。ドライランモードを無効にしてメール/Slack 通知の受信を開始するには、[superset config](https://github.com/apache/superset/blob/master/docker/pythonpath_dev/superset_config.py) で `ALERT_REPORTS_NOTIFICATION_DRY_RUN` を `False` に設定してください。

#### `Dockerfile` で

- チャートとダッシュボードのスクリーンショットを撮るには、ヘッドレスブラウザをインストールする必要があります。現在サポートされているのはFirefoxとChromeのみです。
  > Chrome を選択した場合は、`superset_config.py` で `WEBDRIVER_TYPE` の値を `"chrome"` に変更する必要もあります。

注: [Superset のローカルインストール](/docs/installation/docker-compose/) に従っている場合、必要なすべてのコンポーネント (Firefox ヘッドレス ブラウザー、Redis、Postgres db、celery ワーカー、celery beat) が *dev* docker イメージに存在します。
このガイドで説明されている必要な設定変数を追加するだけです (「詳細設定」を参照)。

開発版以外のDockerイメージ（例えば、安定版リリースの「apache/superset:3.1.0」）を実行している場合、そのイメージにはヘッドレスブラウザは含まれていません。このヘッドレスブラウザは、対象のチャートやダッシュボードを参照するために「superset_worker」コンテナのみで必要です。
ヘッドレスブラウザをインストールして設定するか（以下の「カスタムDockerfile」セクションを参照）、または「docker compose」経由でデプロイする場合は、「docker-compose.yml」ファイルを変更して、ワーカーコンテナには開発版イメージを使用し、「superset_app」コンテナには安定版リリースイメージを使用するようにしてください。

*注*: ここでの「開発イメージ」とは、対応する非開発イメージと同じアプリケーションソフトウェアで、追加ツールがバンドルされているものを指します。つまり、「3.1.0-dev」のようなイメージは、安定性、機能性、本番環境での動作に関しては「3.1.0」と全く同じです。Supersetの実際の「開発中」バージョン（最先端かつ不安定版）は、Docker Hub上でバージョン番号がタグ付けされておらず、Superset UIではバージョン「0.0.0-dev」と表示されます。

### Slack との統合

Slack チャンネルにアラートやレポートを送信するには、ワークスペースに新しい Slack アプリケーションを作成する必要があります。

1. Slack ワークスペースに接続し、[https://api.slack.com/apps] にアクセスします。
2. 新しいアプリを作成します。
3. 「OAuth と権限」セクションに移動し、アプリに以下のスコープを設定します:
   - `incoming-webhook`
   - `files:write`
   - `chat:write`
   - `channels:read`
   - `groups:read`
4. 「OAuth と権限」セクションの上部にある「ワークスペースにインストール」をクリックします。
5. アプリのデフォルトチャンネルを選択し、続行します。（Superset アプリをそのチャンネルに招待することで、どのチャンネルにも投稿できます。）
6. これでアプリがワークスペースにインストールされ、「Bot User OAuth Access Token」が作成されているはずです。このトークンを `superset_config.py` の `SLACK_API_TOKEN` 変数にコピーします。
7. `superset_config.py` で機能フラグ `ALERT_REPORT_SLACK_V2` が True に設定されていることを確認します。
8. 新しい設定を反映させるため、サービスを再起動（または `superset init` を実行）します。

注意: アラートまたはレポートを構成する場合、Slack チャネル リストは先頭の '#' を除いたチャネル名を取得します。たとえば、`#alerts` ではなく `alerts` を使用します。

### Kubernetes 固有の

- `celery beat` ポッドが稼働している必要があります。GitHubリポジトリの [helm/superset](https://github.com/apache/superset/tree/master/helm/superset) に含まれるチャートを使用している場合は、値のオーバーライドに `supersetCeleryBeat.enabled = true` を追加する必要があります。
- 詳細については、[Kubernetes のインストール](/docs/installation/kubernetes) に関する専用ドキュメントをご覧ください。

### Docker Compose 固有の

#### `docker-compose.yml`に以下を含める必要があります

- Redis メッセージブローカー
- SQLlite の代わりに PostgreSQL データベース
- 1 つ以上の `celery worker`
- 1 つの `celery beat`

このプロセスは Docker swarm 環境でも機能します。swarm の特定の構成とともに、Superset、Redis、および Postgres サービスに `Deploy:` を追加するだけです。

### 詳細な設定

以下の設定を `superset_config.py` ファイルに追加する必要があります。このファイルはイメージの実行時に読み込まれ、このファイル内の設定は `config.py` のデフォルト設定を上書きします。

デフォルトの `config.py` の各フィールドに関するドキュメントは、GitHub リポジトリの [superset/config.py](https://github.com/apache/superset/blob/master/superset/config.py) にあります。

デフォルト値を、Redis、Slack、SMTP のカスタム設定に置き換える必要があります。

Superset は、アラートとレポートの送信に Celery beat と Celery worker を使用します。

- beat とは、worker にタスクを実行するタイミングを指示するスケジューラーです。このスケジュールは、アラートまたはレポートの作成時に定義されます。
- worker は、アラートまたはレポートが発行されたときに実行する必要があるタスクを処理します。

`CeleryConfig` では、`beat_schedule` のみがこの機能に関連し、`CeleryConfig` の残りの部分はニーズに合わせて変更できます。

```python
from celery.schedules import crontab

FEATURE_FLAGS = {
    "ALERT_REPORTS": True
}

REDIS_HOST = "superset_cache"
REDIS_PORT = "6379"

class CeleryConfig:
    broker_url = f"redis://{REDIS_HOST}:{REDIS_PORT}/0"
    imports = (
        "superset.sql_lab",
        "superset.tasks.scheduler",
    )
    result_backend = f"redis://{REDIS_HOST}:{REDIS_PORT}/0"
    worker_prefetch_multiplier = 10
    task_acks_late = True
    task_annotations = {
        "sql_lab.get_sql_results": {
            "rate_limit": "100/s",
        },
    }
    beat_schedule = {
        "reports.scheduler": {
            "task": "reports.scheduler",
            "schedule": crontab(minute="*", hour="*"),
        },
        "reports.prune_log": {
            "task": "reports.prune_log",
            "schedule": crontab(minute=0, hour=0),
        },
    }
CELERY_CONFIG = CeleryConfig

SCREENSHOT_LOCATE_WAIT = 100
SCREENSHOT_LOAD_WAIT = 600

# Slack configuration
SLACK_API_TOKEN = "xoxb-"

# Email configuration
SMTP_HOST = "smtp.sendgrid.net" # change to your host
SMTP_PORT = 2525 # your port, e.g. 587
SMTP_STARTTLS = True
SMTP_SSL_SERVER_AUTH = True # If you're using an SMTP server with a valid certificate
SMTP_SSL = False
SMTP_USER = "your_user" # use the empty string "" if using an unauthenticated SMTP server
SMTP_PASSWORD = "your_password" # use the empty string "" if using an unauthenticated SMTP server
SMTP_MAIL_FROM = "noreply@youremail.com"
EMAIL_REPORTS_SUBJECT_PREFIX = "[Superset] " # optional - overwrites default value in config.py of "[Report] "

# WebDriver configuration
# If you use Firefox, you can stick with default values
# If you use Chrome, then add the following WEBDRIVER_TYPE and WEBDRIVER_OPTION_ARGS
WEBDRIVER_TYPE = "chrome"
WEBDRIVER_OPTION_ARGS = [
    "--force-device-scale-factor=2.0",
    "--high-dpi-support=2.0",
    "--headless",
    "--disable-gpu",
    "--disable-dev-shm-usage",
    "--no-sandbox",
    "--disable-setuid-sandbox",
    "--disable-extensions",
]

# This is for internal use, you can keep http
WEBDRIVER_BASEURL = "http://superset:8088" # When running using docker compose use "http://superset_app:8088'
# This is the link sent to the recipient. Change to your domain, e.g. https://superset.mydomain.com
WEBDRIVER_BASEURL_USER_FRIENDLY = "http://localhost:8088"
```

また、ダッシュボードをレンダリングするユーザー名も指定する必要があります。通常、ダッシュボードとチャートは不正なリクエストからはアクセスできないため、ワーカーはスナップショットを取得するために既存ユーザーの認証情報を引き継ぐ必要があります。

デフォルトでは、アラートとレポートはアラート/レポートオブジェクトの所有者として実行されます。固定ユーザーアカウントを使用するには、設定を次のように変更します（この例では「admin」）:

```python
from superset.tasks.types import FixedExecutor

ALERT_REPORTS_EXECUTORS = [FixedExecutor("admin")]
```

その他のエグゼキュータータイプについては、コードベースの「ExecutorType」を参照してください。

**重要事項**

- Celery の同時実行設定（`-c 4` を使用）に注意してください。Selenium/WebDriver インスタンスは、サーバーの CPU / メモリを大量に消費する可能性があります。
- 場合によっては、geckodriver プロセスが大量にリークしていることに気付いた場合は、`celery worker --pool=prefork --max-tasks-per-child=128 ...` を指定して Celery プロセスを実行してみてください。
- `sql_lab` タスクと `email_reports` タスクには別々のワーカーを実行することをお勧めします。これは、`task_annotations` の `queue` フィールドを使用して実行できます。
- Celery ワーカーがデフォルト値の `http://0.0.0.0:8080/` 経由で Superset にアクセスできない場合は、設定ファイルで `WEBDRIVER_BASEURL` を調整してください。

設定ファイルを使用して、各レポートの実行間隔の最小値を指定することもできます。

``` python
# Set a minimum interval threshold between executions (for each Alert/Report)
# Value should be an integer
ALERT_MINIMUM_INTERVAL = int(timedelta(minutes=10).total_seconds())
REPORT_MINIMUM_INTERVAL = int(timedelta(minutes=5).total_seconds())
```

あるいは、`ALERT_MINIMUM_INTERVAL` および/または `REPORT_MINIMUM_INTERVAL` に関数を割り当てることもできます。これは、必要に応じて動的に値を取得するのに便利です:

``` python
def alert_dynamic_minimal_interval(**kwargs) -> int:
    """
    Define logic here to retrieve the value dynamically
    """

ALERT_MINIMUM_INTERVAL = alert_dynamic_minimal_interval
```

## カスタム Dockerfile

リリース済みの Superset イメージの開発版（例：`apache/superset:3.1.0-dev`）を実行している場合は、上記の設定で問題ありません。

ただし、独自のイメージを構築する場合や、非開発版から始める場合は、チャートやダッシュボードのスクリーンショットをキャプチャして受信者に送信するために、Web ドライバー（およびヘッドレスブラウザ）が必要です。
Firefox または Chrome でスクリーンショットを撮影できるように Dockerfile を変更する手順は次のとおりです。

### Firefox の使用

```docker
FROM apache/superset:3.1.0

USER root

RUN apt-get update && \
    apt-get install --no-install-recommends -y firefox-esr

ENV GECKODRIVER_VERSION=0.29.0
RUN wget -q https://github.com/mozilla/geckodriver/releases/download/v${GECKODRIVER_VERSION}/geckodriver-v${GECKODRIVER_VERSION}-linux64.tar.gz && \
    tar -x geckodriver -zf geckodriver-v${GECKODRIVER_VERSION}-linux64.tar.gz -O > /usr/bin/geckodriver && \
    chmod 755 /usr/bin/geckodriver && \
    rm geckodriver-v${GECKODRIVER_VERSION}-linux64.tar.gz

RUN pip install --no-cache gevent psycopg2 redis

USER superset
```

### Chrome の使用

```docker
FROM apache/superset:3.1.0

USER root

RUN apt-get update && \
    apt-get install -y wget zip libaio1

RUN export CHROMEDRIVER_VERSION=$(curl --silent https://googlechromelabs.github.io/chrome-for-testing/LATEST_RELEASE_116) && \
    wget -O google-chrome-stable_current_amd64.deb -q http://dl.google.com/linux/chrome/deb/pool/main/g/google-chrome-stable/google-chrome-stable_${CHROMEDRIVER_VERSION}-1_amd64.deb && \
    apt-get install -y --no-install-recommends ./google-chrome-stable_current_amd64.deb && \
    rm -f google-chrome-stable_current_amd64.deb

RUN export CHROMEDRIVER_VERSION=$(curl --silent https://googlechromelabs.github.io/chrome-for-testing/LATEST_RELEASE_116) && \
    wget -q https://storage.googleapis.com/chrome-for-testing-public/${CHROMEDRIVER_VERSION}/linux64/chromedriver-linux64.zip && \
    unzip -j chromedriver-linux64.zip -d /usr/bin && \
    chmod 755 /usr/bin/chromedriver && \
    rm -f chromedriver-linux64.zip

RUN pip install --no-cache gevent psycopg2 redis

USER superset
```

Chrome を使用する場合は、設定で `WEBDRIVER_TYPE` と `WEBDRIVER_OPTION_ARGS` を設定することを忘れないでください。

## トラブルシューティング

レポートが機能しない理由は様々です。具体的な問題がないか確認するには、以下の手順をお試しください。

### 機能フラグが有効になっており、十分な権限があることを確認してください。

Superset UI の「設定」ドロップダウンの「*管理*」セクションに「アラートとレポート」が表示されない場合は、「ALERT_REPORTS」機能フラグを有効にする必要があります（上記参照）。別の機能フラグを有効にして、それが反映されているかどうかを確認し、構成ファイルが読み込まれていることを確認してください。

管理者ユーザーとしてログインし、十分な権限があることを確認してください。

### Celery ワーカーのログを確認してください。

これは問題に関する最良の情報源です。docker compose デプロイメントでは、`docker logs superset_worker --since 1h` のようなコマンドで確認できます。

### Web ブラウザと WebDriver のインストールを確認してください。

スクリーンショットを撮るには、ワーカーはヘッドレスブラウザを使ってダッシュボードまたはチャートにアクセスし、スクリーンショットを撮ります。チャートをCSVまたはテキストとして送信できるのにPNGとして送信できない場合は、ブラウザに問題がある可能性があります。

`-dev`で終わるタグを持つSuperset Dockerイメージには、Firefoxヘッドレスブラウザとgeckodriverが既にインストールされています。Supersetワーカーに入り、`firefox --headless`と`geckodriver`を実行することで、これらがインストールされ、適切なパスにあることをテストできます。どちらのコマンドでも、これらのアプリケーションが起動するはずです。

これらのソフトウェアを自分でインストールする場合、または代わりにChromiumを使用する場合は、ワーカー環境でヘッドレスブラウザが正常に開くことをご自身で確認してください。

### テストメールを送信する

メールサーバーへの接続が無効であることを示す症状の一つとして、レポートの送信時にログに`[Errno 110] 接続タイムアウト` というエラーが表示されることが挙げられます。

テストを実施して、送信メールの設定が正しいことを確認してください。最も簡単なテストは、ポート25で実行されている認証されていないSMTPメールサービスです。例えばSSL経由で送信する場合は、[Supersetのコードベースがどのようにメールを送信するか](https://github.com/apache/superset/blob/master/superset/utils/core.py#L818)を調べ、それらのコマンドと引数でテストしてください。

ワーカー環境でPythonを起動し、すべてのサンプル値を置き換えて、以下を実行します:

```python
import smtplib
from email.mime.multipart import MIMEMultipart
from email.mime.text import MIMEText

from_email = 'superset_emails@example.com'
to_email = 'your_email@example.com'
msg = MIMEMultipart()
msg['From'] = from_email
msg['To'] = to_email
msg['Subject'] = 'Superset SMTP config test'
message = 'It worked'
msg.attach(MIMEText(message))
mailserver = smtplib.SMTP('smtpmail.example.com', 25)
mailserver.sendmail(from_email, to_email, msg.as_string())
mailserver.quit()
```

これでメールが送信されるはずです。

考えられる解決策:

- 一部のクラウドホストでは、スパム対策として、認証されていないSMTPメールの送信が無効になっています。たとえば、[Azure は一部のマシンでポート25をデフォルトでブロックしています](https://learn.microsoft.com/en-us/azure/virtual-network/troubleshoot-outbound-smtp-connectivity)。このポートを有効にするか、別の送信方法を使用してください。
- この設定で正常に動作することを確認した別のSMTP認証情報を使用してください。

### ワーカーからレポートを参照する

ワーカーがレポートにアクセスできない可能性があります。ワーカーはレポートを参照するために `WEBDRIVER_BASEURL` の値を使用します。このルートが無効であるか、ワーカーが通過できない認証チャレンジがある場合、レポートのスクリーンショットは失敗します。

ワーカーのエラーログに表示されているレポートの URL を `curl` でアクセスして確認してみてください。例えば、ワーカー環境から `curl http://superset_app:8088/superset/dashboard/1/` を実行します。ダッシュボードが存在するかどうかによって、レスポンスが異なる場合があります。例えば、URL の `1` を変更する必要があるかもしれません。ログに失敗したレポートのスクリーンショットの URL がある場合は、そこから確認を始めるのが良いでしょう。目標は、`WEBDRIVER_BASEURL` の有効な値を特定し、HTTPS や認証などの問題によってワーカーがリダイレクトされているかどうかを確認することです。

HTTPS やシングル サインオンなどの認証手段が有効になっているデプロイメントでは、サインインの必要性を回避し、ワーカーが同じ場所で実行されている Superset アプリケーションに直接移動できるようにすることが合理的です。たとえば、docker compose デプロイメントに `WEBDRIVER_BASEURL="http://superset_app:8088"` を使用し、`TALISMAN_CONFIG` で `"force_https": False,` を設定できます。

## クエリをレポートとしてスケジュールする

オプションで、ユーザーがSQL Labで直接クエリをスケジュールできるようにすることができます。これは、保存されたクエリにメタデータを追加することで実現します。メタデータは、外部のスケジュールされたクエリ（[Apache Airflow](https://airflow.apache.org/)など）によって取得されます。

クエリのスケジュールを許可するには、設定ファイルの`SCHEDULED_QUERIES`に以下のコードを追加します:

```python
SCHEDULED_QUERIES = {
    # This information is collected when the user clicks "Schedule query",
    # and saved into the `extra` field of saved queries.
    # See: https://github.com/mozilla-services/react-jsonschema-form
    'JSONSCHEMA': {
        'title': 'Schedule',
        'description': (
            'In order to schedule a query, you need to specify when it '
            'should start running, when it should stop running, and how '
            'often it should run. You can also optionally specify '
            'dependencies that should be met before the query is '
            'executed. Please read the documentation for best practices '
            'and more information on how to specify dependencies.'
        ),
        'type': 'object',
        'properties': {
            'output_table': {
                'type': 'string',
                'title': 'Output table name',
            },
            'start_date': {
                'type': 'string',
                'title': 'Start date',
                # date-time is parsed using the chrono library, see
                # https://www.npmjs.com/package/chrono-node#usage
                'format': 'date-time',
                'default': 'tomorrow at 9am',
            },
            'end_date': {
                'type': 'string',
                'title': 'End date',
                # date-time is parsed using the chrono library, see
                # https://www.npmjs.com/package/chrono-node#usage
                'format': 'date-time',
                'default': '9am in 30 days',
            },
            'schedule_interval': {
                'type': 'string',
                'title': 'Schedule interval',
            },
            'dependencies': {
                'type': 'array',
                'title': 'Dependencies',
                'items': {
                    'type': 'string',
                },
            },
        },
    },
    'UISCHEMA': {
        'schedule_interval': {
            'ui:placeholder': '@daily, @weekly, etc.',
        },
        'dependencies': {
            'ui:help': (
                'Check the documentation for the correct format when '
                'defining dependencies.'
            ),
        },
    },
    'VALIDATION': [
        # ensure that start_date <= end_date
        {
            'name': 'less_equal',
            'arguments': ['start_date', 'end_date'],
            'message': 'End date cannot be before start date',
            # this is where the error message is shown
            'container': 'end_date',
        },
    ],
    # link to the scheduler; this example links to an Airflow pipeline
    # that uses the query id and the output table as its name
    'linkback': (
        'https://airflow.example.com/admin/airflow/tree?'
        'dag_id=query_${id}_${extra_json.schedule_info.output_table}'
    ),
}
```

この設定は [react-jsonschema-form](https://github.com/mozilla-services/react-jsonschema-form) に基づいており、SQL Lab に「Schedule」というメニュー項目を追加します。メニュー項目をクリックすると、クエリのスケジュール設定に必要なメタデータを追加できるモーダルが表示されます。

この情報はエンドポイント `/api/v1/saved_query/` から取得され、JSON メタデータに `schedule_info` が含まれるクエリのスケジュール設定に使用されます。Airflow 以外のスケジューラーの場合は、上記の設定ファイルに簡単にフィールドを追加できます。
