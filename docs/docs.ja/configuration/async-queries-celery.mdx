---
title: Celery 経由の非同期クエリ
hide_title: true
sidebar_position: 4
version: 1
---

# Celery 経由の非同期クエリ

## Celery

大規模な分析データベースでは、数分または数時間かかるクエリを実行することがよくあります。
一般的なWebリクエストのタイムアウト（30～60秒）を超えて実行される長時間実行クエリをサポートするには、Supersetの非同期バックエンドを構成する必要があります。
これは以下の要素で構成されます:

- 1つまたは複数のSupersetワーカー（Celeryワーカーとして実装）。
  `celery worker`コマンドで起動できます。
  関連オプションを表示するには、`celery worker --help`を実行してください。
- Celeryブローカー（メッセージキュー）。Redis または RabbitMQ の使用を推奨します。
- ワーカーがクエリ結果を保存する場所を定義する結果バックエンド

Celeryを設定するには、`superset_config.py` で `CELERY_CONFIG` を定義する必要があります。
ワーカープロセスとウェブサーバープロセスの両方で同じ設定を使用する必要があります。

```python
class CeleryConfig(object):
    broker_url = "redis://localhost:6379/0"
    imports = (
        "superset.sql_lab",
        "superset.tasks.scheduler",
    )
    result_backend = "redis://localhost:6379/0"
    worker_prefetch_multiplier = 10
    task_acks_late = True
    task_annotations = {
        "sql_lab.get_sql_results": {
            "rate_limit": "100/s",
        },
    }

CELERY_CONFIG = CeleryConfig
```

構成を活用するために Celery ワーカーを起動するには、次のコマンドを実行します:

```bash
celery --app=superset.tasks.celery_app:app worker --pool=prefork -O fair -c 4
```

定期的なバックグラウンド ジョブをスケジュールするジョブを開始するには、次のコマンドを実行します:

```bash
celery --app=superset.tasks.celery_app:app beat
```

結果のバックエンドを設定するには、flask_caching.backends.base import BaseCache の派生のインスタンスを superset_config.py の RESULTS_BACKEND 構成キーに渡す必要があります。
Memcached、Redis、S3 (https://pypi.python.org/pypi/s3werkzeugcache) 、メモリ、ファイルシステム（単一サーバー型の設定またはテスト用）を利用できます。
また、独自のキャッシュインターフェースを作成することもできます。`superset_config.py` は次のようになります:

```python
# On S3
from s3cache.s3cache import S3Cache
S3_CACHE_BUCKET = 'foobar-superset'
S3_CACHE_KEY_PREFIX = 'sql_lab_result'
RESULTS_BACKEND = S3Cache(S3_CACHE_BUCKET, S3_CACHE_KEY_PREFIX)

# On Redis
from flask_caching.backends.rediscache import RedisCache
RESULTS_BACKEND = RedisCache(
    host='localhost', port=6379, key_prefix='superset_results')
```

パフォーマンス向上のため、結果のシリアル化に [MessagePack](https://github.com/msgpack/msgpack-python) と [PyArrow](https://arrow.apache.org/docs/python/) が使用されるようになりました。
問題が発生した場合、`superset_config.py` で `RESULTS_BACKEND_USE_MSGPACK = False` を設定することで、これを無効にできます。
既存の環境をアップグレードする場合は、既存の結果キャッシュストアをクリアしてください。

**重要事項**

- Superset クラスター内のすべてのワーカーノードと Web サーバーが _共通のメタデータデータベースを共有_ することが重要です。
  SQLite は同時実行のサポートが限られており、通常はローカルファイルシステム上に存在するため、このコンテキストでは動作しません。

- セットアップ全体で _celery beat のインスタンスは 1 つだけ実行_ する必要があります。
  そうでない場合、バックグラウンドジョブが複数回スケジュールされ、レポートの重複配信、予想以上の負荷/トラフィックの増加などの異常な動作が発生する可能性があります。

- SQL Lab は、データベース設定 (Sources > Databases > Edit record) で **Asynchronous Query Execution** を有効にした場合にのみ、クエリを非同期で実行します。

## Celery Flower

Flower は、Celery クラスターを監視するための Web ベースのツールで、pip からインストールできます。

```bash
pip install flower
```

flower は次のように実行できます:

```bash
celery --app=superset.tasks.celery_app:app flower
```
